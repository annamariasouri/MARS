name: MARS Daily Data Update

on:
  schedule:
    - cron: '0 4 * * *' # Every day at 04:00 UTC
  workflow_dispatch:

jobs:
  update-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Allow pushing changes
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          lfs: true

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          sudo apt-get update && sudo apt-get install -y libhdf5-dev libnetcdf-dev netcdf-bin
          python -m pip install --upgrade pip
          pip install gdown
          pip install -r requirements.txt

      - name: Ensure data directories exist
        run: |
          echo "Creating data directories (without deleting existing data)..."
          mkdir -p data/models
          mkdir -p data/copernicus/env_history
          mkdir -p data/copernicus/model_ready
          mkdir -p data/copernicus/features
          mkdir -p data/copernicus/raw_nc
          mkdir -p data/forecasts
          mkdir -p data/evaluation
          mkdir -p data/logs
          echo "Data directories ready. Existing files preserved."

      - name: Run Copernicus download
        env:
          COPERNICUS_USERNAME: ${{ secrets.COPERNICUS_USERNAME }}
          COPERNICUS_PASSWORD: ${{ secrets.COPERNICUS_PASSWORD }}
          MARS_REGIONS: limassol,thermaikos,peiraeus
          MARS_DATA_DIR: data
          # CI-specific overrides to fail faster and reduce long exponential backoffs
          MARS_MAX_DOWNLOAD_ATTEMPTS: '3'
          MARS_MAX_BACKOFF_SECONDS: '16'
          MARS_DOWNLOAD_TIMEOUT: '60'
        run: |
          echo "Checking if credentials are set (without exposing them)..."
          python -c "import os; print('Username exists:', bool(os.getenv('COPERNICUS_USERNAME'))); print('Password exists:', bool(os.getenv('COPERNICUS_PASSWORD')))"
          python scripts/download_copernicus_day_test.py

      - name: Run MARS forecast
        env:
          MARS_DATA_DIR: data
          MARS_REGIONS: limassol,thermaikos,peiraeus
        run: |
          python scripts/run_daily_forecast.py

      - name: Evaluate forecast accuracy
        env:
          MARS_DATA_DIR: data
        run: |
          echo "Evaluating forecast accuracy against observations..."
          python scripts/evaluate_forecasts.py --region limassol || echo "Limassol evaluation skipped (no data yet)"
          python scripts/evaluate_forecasts.py --region thermaikos || echo "Thermaikos evaluation skipped (no data yet)"
          python scripts/evaluate_forecasts.py --region peiraeus || echo "Peiraeus evaluation skipped (no data yet)"
          echo "Accuracy evaluation complete. Results in data/evaluation/"

      - name: Scan env histories and produce diagnostics
        env:
          MARS_DATA_DIR: data
          MARS_REGIONS: limassol,thermaikos,peiraeus
        run: |
          echo "Scanning env_history files"
          python scripts/scan_env_histories.py || true

      - name: Upload diagnostics artifact
        uses: actions/upload-artifact@v4
        with:
          name: mars-download-diagnostics
          path: |
            data/logs/**
            data/evaluation/**
            data/copernicus/env_history/**
            data/copernicus/model_ready/**

      - name: Check for download errors or no_rows markers (do not fail CI)
        env:
          MARS_DATA_DIR: data
        run: |
          shopt -s nullglob || true
          errs=$(ls data/logs/*.error 2>/dev/null || true)
          nors=$(ls data/logs/*.no_rows 2>/dev/null || true)
          if [ -n "$errs" ] || [ -n "$nors" ]; then
            echo "WARNING: Found download errors or empty processing results. See artifact 'mars-download-diagnostics' for details."
            ls -la data/logs || true
            echo "Continuing pipeline despite download issues."
          else
            echo "No download errors found."
          fi

      - name: Commit and push updated CSVs
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add data/** || true
          git commit -m "Daily data update: $(date -u +'%Y-%m-%d')" || echo "No changes to commit"
          git push
